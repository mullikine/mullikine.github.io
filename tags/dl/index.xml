<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DL on Bodacious Blog</title>
    <link>https://mullikine.github.io/tags/dl/</link>
    <description>Recent content in DL on Bodacious Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Oct 2019 00:00:00 +1300</lastBuildDate>
    
	<atom:link href="https://mullikine.github.io/tags/dl/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Notes on &#34;Math4IQB Hopfield Networks&#34;</title>
      <link>https://mullikine.github.io/posts/notes-on-math4iqb-hopfield-networks/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/notes-on-math4iqb-hopfield-networks/</guid>
      <description>Original video https://www.youtube.com/watch?v=gfPUWwBkXZY  Glossary information gain [data mining] The amount of information that&amp;#39;s gained by knowing the value of the attribute, which is the entropy of the distribution before the split minus the entropy of the distribution after it. The largest information gain is equivalent to the smallest entropy. vim +/&amp;#34;mutual information&amp;#34; &amp;#34;$NOTES/ws/glossaries/information-theory.txt&amp;#34; information gain ratio [#decision tree learning] Ratio of information gain to the intrinsic information. It was proposed by Ross Quinlan, to reduce a bias towards multi-valued attributes by taking the number and size of branches into account when choosing an attribute.</description>
    </item>
    
    <item>
      <title>(WIP) Review of Language, trees, and geometry in neural networks</title>
      <link>https://mullikine.github.io/posts/language-trees-and-geometry-in-neural-networks/</link>
      <pubDate>Mon, 07 Oct 2019 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/language-trees-and-geometry-in-neural-networks/</guid>
      <description>1906.02715 Visualizing and Measuring the Geometry of BERT
https://pair-code.github.io/interpretability/bert-tree/
https://pair-code.github.io/interpretability/context-atlas/blogpost/
Existing representation: word embeddings Language is made of discrete structures, yet neural networks operate on continuous data: vectors in high-dimensional space.
A successful language-processing network must translate this symbolic information into some kind of geometric representationâ€”but in what form?
Word embeddings provide two well-known examples: distance encodes semantic similarity, while certain directions correspond to polarities (e.g. male vs. female).</description>
    </item>
    
  </channel>
</rss>