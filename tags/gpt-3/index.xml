<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GPT-3 on Bodacious Blog</title>
    <link>https://mullikine.github.io/tags/gpt-3/</link>
    <description>Recent content in GPT-3 on Bodacious Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Apr 2021 00:00:00 +1200</lastBuildDate><atom:link href="https://mullikine.github.io/tags/gpt-3/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Imaginary programming with GPT-3</title>
      <link>https://mullikine.github.io/posts/imaginary-programming-with-gpt-3/</link>
      <pubDate>Thu, 08 Apr 2021 00:00:00 +1200</pubDate>
      
      <guid>https://mullikine.github.io/posts/imaginary-programming-with-gpt-3/</guid>
      <description>Code https://github.com/semiosis/pen.el Prompts https://github.com/semiosis/prompts/  Disclaimer: Please contribute as this is an open source project! It&amp;rsquo;s very hard to find free prompts online currently and that&amp;rsquo;s because everyone is out for themselves. Please support open source. Thank you.    Summary This is a demonstration of an imaginary programming environment. There may be nothing else like it in the world today.
What does it mean to be imaginary? Several of the components of a normal programming environment are replaced by functions that infer rather than evaluate.</description>
    </item>
    
    <item>
      <title>Fictional statements of remorse with GPT-3 in the 1st and 3rd person</title>
      <link>https://mullikine.github.io/posts/fictional-statements-of-remorse-with-gpt-3/</link>
      <pubDate>Wed, 07 Apr 2021 00:00:00 +1200</pubDate>
      
      <guid>https://mullikine.github.io/posts/fictional-statements-of-remorse-with-gpt-3/</guid>
      <description>Summary I use GPT-3 to generate fictional statements of remorse.
It should be noted that this is only one such way that GPT-3 will upheave legal process.
RemorseBot (in the 1st person)  --  RemorseBot (in the 3rd person)  --  Prompts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108  title: &amp;#34;Statement of remorse&amp;#34; # future-titles: &amp;#34;&amp;#34; # aims: |+ # - More abstractive rewording doc: &amp;#34;&amp;#34; # aims: |+ # - More abstractive rewording prompt-version: 1 # &amp;lt;:pp&amp;gt; defines a point where the following # text is concatenated before the postprocessor # is run.</description>
    </item>
    
    <item>
      <title>Translating with GPT-3 and Emacs</title>
      <link>https://mullikine.github.io/posts/translating-with-gpt-3-and-emacs/</link>
      <pubDate>Tue, 06 Apr 2021 00:00:00 +1200</pubDate>
      
      <guid>https://mullikine.github.io/posts/translating-with-gpt-3-and-emacs/</guid>
      <description>Subtopics of Ancient Roman Law These were generated by GPT-3.
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  aedilitas advocatus auctoritas augur auspex caupona cena clientela contio domus ius ludos ministra mos ora otium praetor quaestio res mancipi sacerdos status suovetaurilia tabella tribunus plebis via vir    --  GPT-3 Language detection and translation  language Latin  English translation:</description>
    </item>
    
    <item>
      <title>GPT-3 for working out what is better than what (Aggressive humor and satire)</title>
      <link>https://mullikine.github.io/posts/gpt-3-for-working-out-what-is-better-than-what/</link>
      <pubDate>Sat, 03 Apr 2021 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/gpt-3-for-working-out-what-is-better-than-what/</guid>
      <description>AI safety glossary https://github.com/mullikine/glossaries-gh/blob/master/ai-safety.txt  Warning. This is Aggressive humor and Satire This article showcases GPT-3&amp;rsquo;s amazing ability but also is meant to alert you to its dangers.
Summary On AI safety Be aware that GPT-3 has at least these two forms of bias:
1 2 3 4 5 6 7 8 9 10 11 12 13  explicit bias [#ai safety] Where output is clearly toxic (cursing, slander). implicit bias [#ai safety] Where the policy from the output changes based on context (e.</description>
    </item>
    
    <item>
      <title>GPT-3 mind maps with an AI tutor for any topic</title>
      <link>https://mullikine.github.io/posts/gpt-3-for-building-mind-maps-with-an-ai-tutor-for-any-topic/</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/gpt-3-for-building-mind-maps-with-an-ai-tutor-for-any-topic/</guid>
      <description>Code http://github.com/semiosis/pen.el Prompts http://github.com/semiosis/prompts  Summary I combine GPT-3 with org-brain to expand on topics, suggesting subtopics and providing an interactive tutor for any topic.
Demonstration Subtopic generation I demonstrate how to explore arbitrary topics with GPT-3 by automatically generating subtopics, and then allowing you to invoke the GPT-3 tutor to answer questions within that context.
 --  Tutor demonstration  Rolling conversation is a work in progress, but on its way.</description>
    </item>
    
    <item>
      <title>Generating pickup lines with GPT-3</title>
      <link>https://mullikine.github.io/posts/generating-pickup-lines-with-gpt-3/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/generating-pickup-lines-with-gpt-3/</guid>
      <description>Latest version of the pick up lines prompt http://github.com/semiosis/prompts/blob/master/prompts/very-witty-pick-up-lines.prompt  Summary I create a prompt in my prompt description format and use it to generate some pickup lines.
Demonstration (v2 with emacs counsel integration) New results are fed into a fuzzy finder as they are generated. I can stop and select at any time.
 --  Demonstration (version 2)  --  Pick up lines with the topic &amp;ldquo;SETTLERS OF CATAN&amp;rdquo; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  When playing Settlers of Catan, the shortest route is a straight line to my heart.</description>
    </item>
    
    <item>
      <title>Quick demo: Summarizing with huggingface, GPT-3 and others</title>
      <link>https://mullikine.github.io/posts/summarizing-with-huggingface-gpt-3-and-others/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/summarizing-with-huggingface-gpt-3-and-others/</guid>
      <description>Demonstration  Summarizing an arxiv paper Automating arxiv Comparing different GPT-3 prompts Configuration with emacs Developing the automations, pipelines and prompts   -- </description>
    </item>
    
    <item>
      <title>Autocompleting anything with GPT-3 in emacs</title>
      <link>https://mullikine.github.io/posts/autocompleting-anything-with-gpt-3-in-emacs/</link>
      <pubDate>Tue, 16 Mar 2021 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/autocompleting-anything-with-gpt-3-in-emacs/</guid>
      <description>Emacs package http://github.com/mullikine/emacs/blob/master/config/pen.el Prompt http://github.com/semiosis/prompts/blob/master/prompts/generic-file-type-completion.prompt  Summary I make a prompt for the OpenAI API which completes given a file type and some preceding text.
I then make a company-mode completion function for it, and then demo its usage.
This gives me a generic completion mechanism when dealing with any type of document.
Demonstration This is GPT-3 completing some text for me.
I can type a few characters and then GPT-3 will complete the rest of the text.</description>
    </item>
    
    <item>
      <title>Context menus based on GPT-3</title>
      <link>https://mullikine.github.io/posts/context-menus-based-on-gpt-3/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/context-menus-based-on-gpt-3/</guid>
      <description>Summary I create a GPT-3 prompt for testing to see if code is Haskell and use it as a test inside emacs to suggest further functions.
 Prompt file http://github.com/semiosis/prompts/blob/master/prompts/text-is-haskell.prompt  Demonstration As you can see, GPT-3 is able to detect the language and I can use that as a test in my emacs to provide further functions. The suggested function was yet another GPT-3 prompt function for translating Haskell into Clojure.</description>
    </item>
    
    <item>
      <title>spaCy in emacs</title>
      <link>https://mullikine.github.io/posts/spacy-in-emacs/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/spacy-in-emacs/</guid>
      <description>Summary I begin construction of an environment for developing with spaCy.
 Goals  spaCy pipeline builder/wizard Select and analyse text with spaCy linguistic features spaCy python playground text selection configuration of spaCy using emacs custom.el    deplacy demo  deplacy code https://github.com/KoichiYasuoka/deplacy  
Code generation and bindings 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  (defmacro etv-filter (cmd) (let* ((slug (slugify cmd)) (sym (str2sym (concat &amp;#34;etv-&amp;#34; slug)))) `(defun ,sym (&amp;amp;optional input) (interactive (list (my/selected-text))) (if (not input) (setq input (my/selected-text))) (etv (snc ,cmd input))))) (cl-loop for s in &amp;#39;(&amp;#34;partsofspeech&amp;#34; &amp;#34;entities&amp;#34; &amp;#34;displacy&amp;#34; &amp;#34;token-pos-dep&amp;#34; &amp;#34;sentiment&amp;#34; &amp;#34;segment-sentences&amp;#34;) do (eval (expand-macro `(etv-filter ,s)))) (define-key selected-keymap (kbd &amp;#34;Z n&amp;#34;) &amp;#39;ngram-query-replace) (define-key selected-keymap (kbd &amp;#34;Z S&amp;#34;) &amp;#39;sps-play-spacy) (define-key selected-keymap (kbd &amp;#34;Z P&amp;#34;) &amp;#39;etv-partsofspeech) (define-key selected-keymap (kbd &amp;#34;Z E&amp;#34;) &amp;#39;etv-entities) (define-key selected-keymap (kbd &amp;#34;Z D&amp;#34;) &amp;#39;etv-displacy) (define-key selected-keymap (kbd &amp;#34;Z T&amp;#34;) &amp;#39;etv-token-pos-dep) (define-key selected-keymap (kbd &amp;#34;Z N&amp;#34;) &amp;#39;etv-sentiment) (define-key selected-keymap (kbd &amp;#34;Z G&amp;#34;) &amp;#39;etv-segment-sentences)     Configuration yaml I store the configuration of spaCy inside a yaml file.</description>
    </item>
    
    <item>
      <title>An operating system based on GPT-3</title>
      <link>https://mullikine.github.io/posts/an-operating-system-based-on-gpt-3/</link>
      <pubDate>Mon, 08 Mar 2021 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/an-operating-system-based-on-gpt-3/</guid>
      <description>Reference http://github.com/semiosis/examplary  Summary I assume that GPT-3 or some descendant of it will become the primary interface to the computer.
I create a configuration option to enable / disable GPT-3.
When disabled, the environment will resort to alternative means of performing tasks.
Configuration 1  vim +/&amp;#34;use_gpt3: on&amp;#34; &amp;#34;$NOTES/myrc.yaml&amp;#34;     1  vim +/&amp;#34;summarize) {&amp;#34; &amp;#34;$SCRIPTS/s&amp;#34;   If gpt3 is enabled, filter through OpenAI API abstractive summarizer Otherwise, use sumy.</description>
    </item>
    
    <item>
      <title>A natural language database using a single GPT prompt</title>
      <link>https://mullikine.github.io/posts/a-natural-language-database-using-a-single-gpt-prompt/</link>
      <pubDate>Sun, 07 Mar 2021 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/a-natural-language-database-using-a-single-gpt-prompt/</guid>
      <description>Original article https://www.gwern.net/GPT-3#the-database-prompt  Summary A single prompt describes transactions to and from a database.
GPT-3 is able to answer questions about the transactions that have taken place.
GPT-3 isn&amp;rsquo;t actually a database.
The LM simply understands language so well that describing the transactions that have taken place would naturally lead to the GPT-3 response.
The prompt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  title: &amp;#34;database example&amp;#34; doc: &amp;#34;GPT-3 as a NL interface for semantically querying logic in prose&amp;#34; prompt: |+The database begins knowing nothing.</description>
    </item>
    
    <item>
      <title>Translating Haskell to Clojure with GPT-3</title>
      <link>https://mullikine.github.io/posts/translating-haskell-to-clojure-with-gpt-3/</link>
      <pubDate>Sun, 07 Mar 2021 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/translating-haskell-to-clojure-with-gpt-3/</guid>
      <description>Relevant material https://hyperpolyglot.org/ml  Summary Who needs hyperpolyglot when you have GPT-3?
I translate Haskell into Clojure using the following prompt.
haskell-to-clojure.prompt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  title: &amp;#34;Translate Haskell to Clojure&amp;#34; prompt: |+Haskell: zip (map show [1,5,9]) [&amp;#34;a&amp;#34;,&amp;#34;b&amp;#34;,&amp;#34;c&amp;#34;] Clojure: (println (map vector &amp;#39;(1 2 3) &amp;#39;(4 5 6))) Haskell: map toUpper &amp;#34;MiXeD cAsE&amp;#34; Clojure: (clojure.</description>
    </item>
    
    <item>
      <title>crontab.guru in emacs and making a prompt with GPT-3 to copy it</title>
      <link>https://mullikine.github.io/posts/crontab-guru-in-emacs/</link>
      <pubDate>Sat, 06 Mar 2021 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/crontab-guru-in-emacs/</guid>
      <description>Related https://crontab.guru/  Summary I build some functionality into emacs to use crontab.guru behind the scenes to interpret tab lines displaying inside of emacs, without using the web browser.
I then build a GPT-3 prompt which does exactly the same thing without crontab.guru and provide the initial script I made to examplary (my GPT-3 DSL) as an example generator, to enhance the prompt if that is needed later.
Initial steps When lines in cron format appear in an emacs buffer, the crontab-guru function is suggested, allowing you to easily understand crontabs.</description>
    </item>
    
    <item>
      <title>Fine-tuning GPT-3</title>
      <link>https://mullikine.github.io/posts/fine-tuning-gpt-3/</link>
      <pubDate>Sun, 21 Feb 2021 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/fine-tuning-gpt-3/</guid>
      <description>Notes on GPT-3 fine-tuning http://github.com/mullikine/fine-tuning-gpt-3  Fine-tuning GPT-3 to generate puns Aims Train GPT-3 to continue on sequences of puns Train GPT-3 to speak in puns Training Data    format     jsonl       Sources
 https://github.com/taivop/joke-dataset       Naive approach
1 2 3  [{&amp;#34;data&amp;#34; : &amp;#34;joke set 1&amp;#34;}, {&amp;#34;data&amp;#34;: &amp;#34;joke set 2&amp;#34;}         Better approach</description>
    </item>
    
  </channel>
</rss>
