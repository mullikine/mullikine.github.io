<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GPT-3 on Bodacious Blog</title>
    <link>https://mullikine.github.io/tags/gpt-3/</link>
    <description>Recent content in GPT-3 on Bodacious Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Jun 2021 00:00:00 +1200</lastBuildDate><atom:link href="https://mullikine.github.io/tags/gpt-3/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>nlsh (Natural Language Shell) with GPT-3</title>
      <link>https://mullikine.github.io/posts/nlsh-natural-language-shell/</link>
      <pubDate>Wed, 16 Jun 2021 00:00:00 +1200</pubDate>
      
      <guid>https://mullikine.github.io/posts/nlsh-natural-language-shell/</guid>
      <description>Summary I extend my openai-complete script with REPL capabilities and use it to create parameterised nlsh REPLs for different Operating Systems.
I use comint, the emacs mode for managing REPLs and rlwrap to manage history and allow me to run the REPL without emacs.
I also generalise it within my prompt description format as &amp;ldquo;conversation mode&amp;rdquo; which enables me to have rolling conversations with a prompt.
So far, I have not implemented any kind of pseudo-memory system for rolling conversation.</description>
    </item>
    
  </channel>
</rss>
