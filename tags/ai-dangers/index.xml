<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI-dangers on Bodacious Blog</title>
    <link>https://mullikine.github.io/tags/ai-dangers/</link>
    <description>Recent content in AI-dangers on Bodacious Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 03 Apr 2021 00:00:00 +1300</lastBuildDate><atom:link href="https://mullikine.github.io/tags/ai-dangers/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>GPT-3 for working out what is better than what (Aggressive humor and satire)</title>
      <link>https://mullikine.github.io/posts/gpt-3-for-working-out-what-is-better-than-what/</link>
      <pubDate>Sat, 03 Apr 2021 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/gpt-3-for-working-out-what-is-better-than-what/</guid>
      <description>AI safety glossary https://github.com/mullikine/glossaries-gh/blob/master/ai-safety.txt  Warning. This is Aggressive humor and Satire This article showcases GPT-3&amp;rsquo;s amazing ability but also is meant to alert you to its dangers.
Summary On AI safety Be aware that GPT-3 has at least these two forms of bias:
1 2 3 4 5 6 7 8 9 10 11 12 13  explicit bias [#ai safety] Where output is clearly toxic (cursing, slander). implicit bias [#ai safety] Where the policy from the output changes based on context (e.</description>
    </item>
    
  </channel>
</rss>
