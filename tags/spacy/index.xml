<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spaCy on Bodacious Blog</title>
    <link>https://mullikine.github.io/tags/spacy/</link>
    <description>Recent content in spaCy on Bodacious Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Dec 2019 00:00:00 +1300</lastBuildDate>
    
	<atom:link href="https://mullikine.github.io/tags/spacy/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Named Entity Recognition</title>
      <link>https://mullikine.github.io/posts/named-entity-recognition/</link>
      <pubDate>Wed, 04 Dec 2019 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/named-entity-recognition/</guid>
      <description>Original article Named Entity Recognition with NLTK and SpaCy - Towards Data Science Code https://github.com/susanli2016/NLP-with-Python/blob/master/NER%5FNLTK%5FSpacy.ipynb My fork https://github.com/mullikine/NLP-with-Python/blob/master/NER%5FNLTK%5FSpacy.py Related articles Part of Speech Labels // Bodacious Blog  1  sp $MYGIT/susanli2016/NLP-with-Python/NER_NLTK_Spacy.py   Missing libraries 1 2 3 4 5  Resource averaged_perceptron_tagger not found. Please use the NLTK Downloader to obtain the resource: &amp;gt;&amp;gt;&amp;gt; import nltk &amp;gt;&amp;gt;&amp;gt; nltk.download(&amp;#39;averaged_perceptron_tagger&amp;#39;)   1 2 3  import nltk nltk.download(&amp;#39;averaged_perceptron_tagger&amp;#39;) # and then type &amp;#39;d&amp;#39; for download and install &amp;#39;punkt&amp;#39;   I had to do it again for this 1 2  import nltk nltk.</description>
    </item>
    
    <item>
      <title>spaCy</title>
      <link>https://mullikine.github.io/posts/spacy/</link>
      <pubDate>Wed, 04 Dec 2019 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/spacy/</guid>
      <description>Original gist https://gist.github.com/aparrish/697b7f56ac28f4e59af77a66ac573b8f  After loading into spacy Right off the bat, the spaCy library gives us access to a number of interesting units of text:
   code description     doc.sents sentences   doc words   doc.ents named entitites   doc.noun_chunks nouns in the text plus surrounding matter like adjectives and articles    1 2 3 4  sentences = list(doc.</description>
    </item>
    
    <item>
      <title>Reading YouTube rather than watching it</title>
      <link>https://mullikine.github.io/posts/reading-youtube-rather-than-watching-it/</link>
      <pubDate>Wed, 18 Sep 2019 00:00:00 +1200</pubDate>
      
      <guid>https://mullikine.github.io/posts/reading-youtube-rather-than-watching-it/</guid>
      <description>It all starts with youtube-dl youtube-dl is a YouTube video downloader. You can install it with sudo pip install youtube-dl.
Let&amp;rsquo;s make some scripts Use the spaCy NLP library to semantically segregate sentences.
Segment-sentences 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  #!/usr/bin/env python3.5 #!/usr/bin/env python3.6 # -*- coding: utf-8 -*- # python3.6 -m spacy download en import sys import spacy text = sys.</description>
    </item>
    
  </channel>
</rss>