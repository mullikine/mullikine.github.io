<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>parsers on Bodacious Blog</title>
    <link>https://mullikine.github.io/tags/parsers/</link>
    <description>Recent content in parsers on Bodacious Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 25 May 2020 00:00:00 +0800</lastBuildDate>
    
	<atom:link href="https://mullikine.github.io/tags/parsers/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Using github semantic parser</title>
      <link>https://mullikine.github.io/posts/using-github-semantic-parser/</link>
      <pubDate>Mon, 25 May 2020 00:00:00 +0800</pubDate>
      
      <guid>https://mullikine.github.io/posts/using-github-semantic-parser/</guid>
      <description>Links https://github.com/github/semantic#usage  Demonstration 
Set up docker with GitHub https://help.github.com/en/packages/using-github-packages-with-your-projects-ecosystem/configuring-docker-for-use-with-github-packages
1  myrc .github_packages_token | docker login https://docker.pkg.github.com -u mullikine --password-stdin   https://github.com/settings/tokens
Install the package from GitHub&amp;rsquo;s docker registry https://github.com/github/semantic/packages/11609
1  docker pull docker.pkg.github.com/github/semantic/semantic:sha_248a1b3646643613960e444fe8ab6623224d47b1   Create the semantic-parse wrapper script 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  #!</description>
    </item>
    
    <item>
      <title>Parsr</title>
      <link>https://mullikine.github.io/posts/parsr/</link>
      <pubDate>Tue, 21 Jan 2020 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/parsr/</guid>
      <description>Playing around with lazydocker, Parsr and jq 
Running the parser 1  cd &amp;#34;$MYGIT/axa-group/Parsr/docs&amp;#34;; npm run run:debug -- --input-file samples/bitcoin.pdf --output-folder dist/ --document-name example --config server/defaultConfig.json --pretty-logs   1  vs $MYGIT/axa-group/Parsr/dist/example.txt   1  cat $MYGIT/axa-group/Parsr/dist/example.json | jiq   Parsr is kinda cool It parses documents, provides you with a gui to find what you want and then a json parse tree.
  1  cat $MYGIT/axa-group/Parsr/dist/example.</description>
    </item>
    
    <item>
      <title>Review of &#39;Grammars for programming languages - Mikhail Barash - Medium&#39;</title>
      <link>https://mullikine.github.io/posts/review-of-grammars-for-programming-languages-mikhail-barash-medium/</link>
      <pubDate>Tue, 21 Jan 2020 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/review-of-grammars-for-programming-languages-mikhail-barash-medium/</guid>
      <description>Original article https://medium.com/@mikhail.barash.mikbar/grammars-for-programming-languages-fae3a72a22c6 See also https://mullikine.github.io/posts/rosie-pattern-matching-language/  CFG (context-free grammars) When syntax of programming languages is communicated CGFs are a lingua franca.
They define structure of syntax, but cannot express static semantics.
Limitations Soon after context-free grammars had been introduced, it became apparent that their expressive power is limited.
In 1962, Floyd has shown that Algol is not a context-free language and thus cannot be defined by a context-free grammar.</description>
    </item>
    
    <item>
      <title>Monad transformers</title>
      <link>https://mullikine.github.io/posts/monad-transformers/</link>
      <pubDate>Thu, 28 Nov 2019 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/monad-transformers/</guid>
      <description>Original resource https://wiki.haskell.org/Meta-tutorial  grok haskell monad transformers  Original article http://blog.sigfpe.com/2006/05/grok-haskell-monad-transformers.html  State monad 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  import Control.Monad.Identity import Control.Monad.State test1 = do a &amp;lt;- get modify (+1) b &amp;lt;- get return (a,b) test2 = do a &amp;lt;- get modify (++&amp;#34;1&amp;#34;) b &amp;lt;- get return (a,b) go1 = evalState test1 0 go2 = evalState test2 &amp;#34;0&amp;#34; :t go1 go1 :t go2 go2 &amp;#34;**************&amp;#34; :t get :i get &amp;#34;**************&amp;#34; :t modify :i modify &amp;#34;**************&amp;#34; :t evalState :i evalState   go1 :: (Integer, Integer) (0,1) go2 :: ([Char], [Char]) (&amp;#34;0&amp;#34;,&amp;#34;01&amp;#34;) &amp;#34;**************&amp;#34; get :: MonadState s m =&amp;gt; m s class Monad m =&amp;gt; MonadState s (m :: * -&amp;gt; *) | m -&amp;gt; s where get :: m s .</description>
    </item>
    
    <item>
      <title>Deconstructing IPTables-Metalanguage</title>
      <link>https://mullikine.github.io/posts/deconstructing-iptables-metalanguage/</link>
      <pubDate>Mon, 25 Nov 2019 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/deconstructing-iptables-metalanguage/</guid>
      <description>Main.hs 1 2 3 4 5 6 7  ./Main.hs:4:import Test.Framework (defaultMain, testGroup) ./Main.hs:6:import Test.Framework.Providers.QuickCheck2 (testProperty) ./Main.hs:11:import Text.ParserCombinators.Parsec ./Main.hs:13:import Text.IptablesMetalanguage.Types ./Main.hs:14:import Text.IptablesMetalanguage.Parser ./Main.hs:15:import Text.IptablesMetalanguage.Print ./Main.hs:17:import GHC.Word   Test.Framework http://hackage.haskell.org/package/HTF
Tutorial http://hackage.haskell.org/package/HTF-0.14.0.0/docs/Test-Framework-Tutorial.html
defaultMain testGroup Parser.hs 1 2 3 4 5 6 7 8  ./src/Text/IptablesMetalanguage/Parser.hs:4:import Text.IptablesMetalanguage.Types ./src/Text/IptablesMetalanguage/Parser.hs:5:import Control.Applicative ((&amp;lt;$&amp;gt;)) ./src/Text/IptablesMetalanguage/Parser.hs:6:import Control.Monad.Error ./src/Text/IptablesMetalanguage/Parser.hs:7:import Data.Bits ./src/Text/IptablesMetalanguage/Parser.hs:8:import Data.Set (fromList) ./src/Text/IptablesMetalanguage/Parser.hs:9:import Data.Word ./src/Text/IptablesMetalanguage/Parser.hs:10:import Safe ./src/Text/IptablesMetalanguage/Parser.hs:11:import Text.ParserCombinators.Parsec   Types.hs 1 2  ./src/Text/IptablesMetalanguage/Types.hs:4:import Data.Set .</description>
    </item>
    
    <item>
      <title>Rosie Pattern Matching Language (RPL)</title>
      <link>https://mullikine.github.io/posts/rosie-pattern-matching-language/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/rosie-pattern-matching-language/</guid>
      <description>Will regex remain relevant? Probably. Rosie Pattern Language: Why Create a Regex Replacement? Regex are ubiquitous because they fill a persistent need. Today, we rely on regex in so many ways, including:  lexical analysis for the vast majority of programming language parsers;  lexical analysis for Natural Language Processing;  lexical analysis for parsing serialized data formats (JSON, yaml, XML, etc.);  searching within text editors;  operations, in scripts that search and manipulate configuration files, log files, the output of other programs, and more;  development, in tools that manage source code, issues, builds, and tests.</description>
    </item>
    
    <item>
      <title>CodeLingo vs Linters</title>
      <link>https://mullikine.github.io/codelingo-vs-linters/main/</link>
      <pubDate>Fri, 05 Oct 2018 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/codelingo-vs-linters/main/</guid>
      <description>Making tenets with CLQL that do the job of existing linters I started learning Go and CodeLingo / CLQL at the same time, so while I have found it generally easy and straightforward to create these tenets, I feel like I could&amp;rsquo;ve knocked them out even faster if I didn&amp;rsquo;t need to look up answers to questions such as &amp;lsquo;what is an interface in golang?&#39;, for example. The process has been intuitive; I think in part to having a good naming convention.</description>
    </item>
    
    <item>
      <title>CodeLingo vs Linters: TLDR</title>
      <link>https://mullikine.github.io/codelingo-vs-linters/summary/</link>
      <pubDate>Fri, 05 Oct 2018 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/codelingo-vs-linters/summary/</guid>
      <description>Tenet&amp;rsquo;s are 10x shorter and faster to write than Linters Comparison of size in code
   Lines (CL) Lines (L) Words (CL) Words (L) Bytes (CL) Bytes (L) Byte % (CL/L) Tenet name (CL) linter name (L)     18 681 49 2084 524 15616 3.36% unconvert unconvert   19 110 64 275 580 2198 26.39% init gochecknoinits   18 136 67 353 623 2307 27.</description>
    </item>
    
    <item>
      <title>Write You A Haskell</title>
      <link>https://mullikine.github.io/posts/write-you-a-haskell/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://mullikine.github.io/posts/write-you-a-haskell/</guid>
      <description>This is just a casual writeup of WYAH as I read through it.
 Original article http://dev.stephendiehl.com/fun/ http://dev.stephendiehl.com/fun/002%5Fparsers.html Code https://github.com/sdiehl/write-you-a-haskell  We will build a small functional language called Fun which is a partial Haskell 2010 toy language; complete with:
 a parser type inference datatypes pattern matching desugaring typeclasses higher-kinded types monadic IO arbitrary-rank polymorphism records Core language STG intermediate language lazy evaluation interpreter native code generator a runtime, and several optimization passes.</description>
    </item>
    
  </channel>
</rss>