<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>latex on Bodacious Blog</title>
    <link>https://mullikine.github.io/tags/latex/</link>
    <description>Recent content in latex on Bodacious Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Nov 2019 00:00:00 +1300</lastBuildDate>
    
	<atom:link href="https://mullikine.github.io/tags/latex/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Latex and Machine Learning</title>
      <link>https://mullikine.github.io/posts/machine-learning/</link>
      <pubDate>Mon, 04 Nov 2019 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/machine-learning/</guid>
      <description>Information Gain  Original article Information Gain and Mutual Information for Machine Learning  \begin{equation} \mathbf{IG}(\mathbf{S}, a) = \mathbf{H}(\mathbf{S}) – \mathbf{H}(\mathbf{S} | a) \end{equation}
Mutual information Concerns the outcome of two random variables.
If we know the value of one of the random variables in a system there is a corresponding reduction in uncertainty for predicting the other one and mutual information measures that reduction in uncertainty.
\begin{equation} \textbf{I}(X_1 ; X_2) = \sum_{X_1} \sum_{X_2} = \textbf{H}(X_1) - \textbf{H}(X_1 | X_2) \end{equation}</description>
    </item>
    
    <item>
      <title>Entropy, Cross-Entropy and KL-Divergence</title>
      <link>https://mullikine.github.io/posts/entropy-cross-entropy-and-kl-divergence/</link>
      <pubDate>Sat, 02 Nov 2019 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/entropy-cross-entropy-and-kl-divergence/</guid>
      <description>Original video A Short Introduction to Entropy, Cross-Entropy and KL-Divergence - YouTube  Glossary 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95  entropy expected information Measures the average amount of information that you get when you learn the weather each day, or more generally the average amount of information that you get from one sample drawn from a given probability distribution p.</description>
    </item>
    
    <item>
      <title>Variational Inference</title>
      <link>https://mullikine.github.io/posts/variational-inference/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/variational-inference/</guid>
      <description>Original article https://fabiandablander.com/r/Variational-Inference.html  Prereading https://mullikine.github.io/posts/entropy-cross-entropy-and-kl-divergence/
Bayes&amp;rsquo; Theorm 1 2 3 4 5 6 7 8 9 10 11  \begin{equation} \underbrace{p(\mathbf{z} \mid \mathbf{x})}_{\text{Posterior}} = \underbrace{p(\mathbf{z})}_{\text{Prior}} \times \frac{\overbrace{p(\mathbf{x} \mid \mat hbf{z})}^{\text{Likelihood}}}{\underbrace{\int p(\mathbf{x} \mid \mathbf{z}) \, p(\mathbf{z}) \, \mathrm{d}\mathbf{z}}_{\text{Marginal Likelihood}}} \enspace , \end{equation} where $\mathbf{z}$ denotes latent parameters we want to infer and $\mathbf{x}$ denotes data.   \begin{equation} \underbrace{p(\mathbf{z} \mid \mathbf{x})}_{\text{Posterior}} = \underbrace{p(\mathbf{z})}_{\text{Prior}} \times \frac{\overbrace{p(\mathbf{x} \mid \mathbf{z})}^{\text{Likelihood}}}{\underbrace{\int p(\mathbf{x} \mid \mathbf{z}) \, p(\mathbf{z}) \, \mathrm{d}\mathbf{z}}_{\text{Marginal Likelihood}}} \enspace , \end{equation}</description>
    </item>
    
    <item>
      <title>LaTeX in emacs</title>
      <link>https://mullikine.github.io/posts/latex-in-emacs/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/latex-in-emacs/</guid>
      <description>Prereading Compounding Confoundment: arbitrary interpreters for Babel // Bodacious Blog
Setup Create the texalg2png script #!/bin/bash export TTY read -r -d &amp;#39;&amp;#39; texcode &amp;lt;&amp;lt;HEREDOC \documentclass{standalone} \usepackage{varwidth} \usepackage{algorithm} %ctan.org\pkg\algorithms \usepackage{algpseudocode} \begin{document} \begin{varwidth}{\linewidth} \par\noindent \begin{algorithmic}[1] $(cat) \end{algorithmic} \end{varwidth} \end{document} HEREDOC printf -- &amp;#34;%s&amp;#34; &amp;#34;$texcode&amp;#34; | tex2png &amp;#34;$@&amp;#34; Create the tex2png script #!/bin/bash export TTY tf_tex=&amp;#34;$(ux tf tex || echo /dev/null)&amp;#34; trap &amp;#34;rm \&amp;#34;$tf_tex\&amp;#34; 2&amp;gt;/dev/null&amp;#34; 0 fp=&amp;#34;$tf_tex&amp;#34; name=&amp;#34;$1&amp;#34; if test &amp;#34;$name&amp;#34; = nil; then name=&amp;#34;&amp;#34; fi fn=$(basename &amp;#34;$fp&amp;#34;) dn=$(dirname &amp;#34;$fp&amp;#34;) ext=&amp;#34;${fn##*.</description>
    </item>
    
    <item>
      <title>Just a fun bit of math in my day</title>
      <link>https://mullikine.github.io/posts/fun-math/</link>
      <pubDate>Fri, 25 Oct 2019 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/fun-math/</guid>
      <description>Useful mathematical symbols    symbol tex digraph how it reads      &amp;lt;:   is a subtype of    ⊧ \vDash &amp;lt;bar&amp;gt; = entails    ⊢ \vdash &amp;lt;bar&amp;gt; - infers    → \to -&amp;gt; is mapped to maps sets to sets   ↦ \mapsto &amp;lt;bar&amp;gt; &amp;gt; is mapped to maps elements to elements    Euler&amp;rsquo;s Characteristic The second most beautiful equation and its surprising applications - YouTube</description>
    </item>
    
    <item>
      <title>Compounding Confoundment: arbitrary interpreters for Babel</title>
      <link>https://mullikine.github.io/posts/arbitrary-interpreters-for-babel/</link>
      <pubDate>Sun, 20 Oct 2019 00:00:00 +1300</pubDate>
      
      <guid>https://mullikine.github.io/posts/arbitrary-interpreters-for-babel/</guid>
      <description>Genesis 11:7 “&amp;hellip;Come, let us go down and confuse their language so they will not understand each other.” If supporting many languages in Babel was not confounding enough, lets support arbitrary interpreters too!  The need to specify a custom interpreter arose when I needed to provide my own interpreter for generating an ASCII graph from a dot script.
Objective Specify an :interpreter and/or :filter command to override the execute behaviour.</description>
    </item>
    
  </channel>
</rss>