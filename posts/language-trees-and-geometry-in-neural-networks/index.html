<!doctype html>
<html lang="en-us">
  <head>
    <title>(WIP) Review of Language, trees, and geometry in neural networks // Bodacious Blog</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.59.0-DEV" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="John Doe" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://mullikine.github.io/css/main.min.45cc45217000f7775f5af96a21e710dbfc6b9a6fdbe051640e5722b0cbeadf4c.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="(WIP) Review of Language, trees, and geometry in neural networks"/>
<meta name="twitter:description" content="1906.02715 Visualizing and Measuring the Geometry of BERT
https://pair-code.github.io/interpretability/bert-tree/
https://pair-code.github.io/interpretability/context-atlas/blogpost/
Existing representation: word embeddings Language is made of discrete structures, yet neural networks operate on continuous data: vectors in high-dimensional space.
A successful language-processing network must translate this symbolic information into some kind of geometric representation‚Äîbut in what form?
Word embeddings provide two well-known examples: distance encodes semantic similarity, while certain directions correspond to polarities (e.g. male vs. female)."/>

    <meta property="og:title" content="(WIP) Review of Language, trees, and geometry in neural networks" />
<meta property="og:description" content="1906.02715 Visualizing and Measuring the Geometry of BERT
https://pair-code.github.io/interpretability/bert-tree/
https://pair-code.github.io/interpretability/context-atlas/blogpost/
Existing representation: word embeddings Language is made of discrete structures, yet neural networks operate on continuous data: vectors in high-dimensional space.
A successful language-processing network must translate this symbolic information into some kind of geometric representation‚Äîbut in what form?
Word embeddings provide two well-known examples: distance encodes semantic similarity, while certain directions correspond to polarities (e.g. male vs. female)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mullikine.github.io/posts/language-trees-and-geometry-in-neural-networks/" />
<meta property="article:published_time" content="2019-10-07T00:00:00+13:00" />
<meta property="article:modified_time" content="2019-10-07T00:00:00+13:00" /><meta property="og:site_name" content="Bodacious Blog" />


  </head>
  <body>
    <header class="app-header">
      <a href="https://mullikine.github.io"><img class="app-header-avatar" src="http://mullikine.github.io/brainy.png" alt="John Doe" /></a>
      <h1>Bodacious Blog</h1>
      <p>Biosemiotics üåª Xenolingustics üëΩ and emacs üêÑ</p>
      <div class="app-header-social">
        
          <a target="_blank" href="https://github.com/mullikine"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg></a>
        
          <a target="_blank" href="https://linkedin.com/in/shane-mulligan-811b942b/"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-linkedin">
  <title>linkedin</title>
  <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle>
</svg></a>
        
          <a target="_blank" href="https://gitlab.com/mullikine"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-gitlab">
  <title>gitlab</title>
  <path d="M22.65 14.39L12 22.13 1.35 14.39a.84.84 0 0 1-.3-.94l1.22-3.78 2.44-7.51A.42.42 0 0 1 4.82 2a.43.43 0 0 1 .58 0 .42.42 0 0 1 .11.18l2.44 7.49h8.1l2.44-7.51A.42.42 0 0 1 18.6 2a.43.43 0 0 1 .58 0 .42.42 0 0 1 .11.18l2.44 7.51L23 13.45a.84.84 0 0 1-.35.94z"></path>
</svg></a>
        
          <a target="_blank" href="https://www.facebook.com/shrubgrub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-facebook">
  <title>facebook</title>
  <path d="M18 2h-3a5 5 0 0 0-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 0 1 1-1h3z"></path>
</svg></a>
        
          <a target="_blank" href="https://twitter.com/mullikine"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-twitter">
  <title>twitter</title>
  <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path>
</svg></a>
        
        <a href="https://mullikine.github.io/cv/">CV</a>
      </div>
<div class="highlights">
<a href="https://mullikine.github.io/posts/practical-macros-in-racket-and-how-to-work-with-them/">Practical macros in Racket</a>
<br />
<a href="https://mullikine.github.io/posts/github-search-with-bigquery/">Searching GitHub with BigQuery</a>
<br />
<a href="https://mullikine.github.io/posts/review-of-the-illustrated-transformer/">The Illustrated Transformer</a>
<br />
<a href="https://mullikine.github.io/codelingo-vs-linters/main/">CodeLingo vs Linters</a>
<br />
<a href="https://mullikine.github.io/glossary.html">Glossary A-Z (70 topics)</a>
<div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">(WIP) Review of Language, trees, and geometry in neural networks</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Oct 7, 2019
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          1 min read
        </div></div>
    </header>
    

<link rel="stylesheet" type="text/css" href="https://mullikine.github.io/css/magit.css"/>

<script src="https://mullikine.github.io/js/mathjax-config.js"></script>
 
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML"></script>


    <div class="post-content">
      

<p><a href="https://arxiv.org/abs/1906.02715"> 1906.02715  Visualizing and Measuring the Geometry of BERT</a></p>

<p><a href="https://pair-code.github.io/interpretability/bert-tree/">https://pair-code.github.io/interpretability/bert-tree/</a></p>

<p><a href="https://pair-code.github.io/interpretability/context-atlas/blogpost/">https://pair-code.github.io/interpretability/context-atlas/blogpost/</a></p>

<h2 id="existing-representation-word-embeddings">Existing representation: word embeddings</h2>

<p>Language is made of discrete structures, yet
neural networks operate on continuous data:
vectors in high-dimensional space.</p>

<p>A successful language-processing network must
translate this symbolic information into some
kind of geometric representation‚Äîbut in what
form?</p>

<p>Word embeddings provide two well-known
examples: distance encodes semantic
similarity, while certain directions
correspond to polarities (e.g. male vs.
female).</p>

<h2 id="new-representation">New representation</h2>

<p>A recent, fascinating discovery points to an
entirely new type of representation.</p>

<p>One of the key pieces of linguistic
information about a sentence is its syntactic
structure.</p>

<p>This structure can be represented as a tree
whose nodes correspond to words of the
sentence.</p>

<p>Hewitt and Manning, in A structural probe for
finding syntax in word representations, show
that several language-processing networks
construct geometric copies of such syntax
trees.</p>

<p>Words are given locations in a high-
dimensional space, and (following a certain
transformation)</p>

<p>Euclidean distance between these locations
maps to tree distance.</p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
