<!doctype html>
<html lang="en-us">
  <head>
    <title>Review of &#39;Google AI Blog: PEGASUS: A State-of-the-Art Model for Abstractive Text Summarization&#39; // Bodacious Blog</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.82.0-DEV" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Shane Mulligan" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://mullikine.github.io/css/main.min.8b2233c557881de0c8566bf9ec6b236d5ad6653bcaee2e6a73f0776d0ee288e1.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Review of &#39;Google AI Blog: PEGASUS: A State-of-the-Art Model for Abstractive Text Summarization&#39;"/>
<meta name="twitter:description" content="Original article Google AI Blog: PEGASUS: A State-of-the-Art Model for Abstractive Text Summarization Source code GitHub - google-research/pegasus text summarization one of the most challenging tasks in natural language processing, involving understanding of long passages, information compression, and language generation.  The dominant paradigm for training ML models to do this is seq2seq learning, where a NN learns to map input sequences to output sequences.
seq2seq models were initially developed using RNN."/>

    <meta property="og:title" content="Review of &#39;Google AI Blog: PEGASUS: A State-of-the-Art Model for Abstractive Text Summarization&#39;" />
<meta property="og:description" content="Original article Google AI Blog: PEGASUS: A State-of-the-Art Model for Abstractive Text Summarization Source code GitHub - google-research/pegasus text summarization one of the most challenging tasks in natural language processing, involving understanding of long passages, information compression, and language generation.  The dominant paradigm for training ML models to do this is seq2seq learning, where a NN learns to map input sequences to output sequences.
seq2seq models were initially developed using RNN." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mullikine.github.io/posts/review-of-google-ai-blog-pegasus-a-state-of-the-art-model-for-abstractive-text-summarization/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-06-13T00:00:00&#43;08:00" />
<meta property="article:modified_time" content="2020-06-13T00:00:00&#43;08:00" /><meta property="og:site_name" content="Bodacious Blog" />



    
    <script type="text/javascript">
      var _paq = window._paq = window._paq || [];
       
      _paq.push(['trackPageView']);
      _paq.push(['enableLinkTracking']);
      (function() {
        var u="https://mullikine.matomo.cloud/";
        _paq.push(['setTrackerUrl', u+'matomo.php']);
        _paq.push(['setSiteId', '1']);
        var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
        g.type='text/javascript'; g.async=true; g.src='//cdn.matomo.cloud/mullikine.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
      })();
    </script>
    

  </head>
  <body>
    <header class="app-header">

<a href="https://mullikine.github.io"><img class="app-header-avatar" src="http://mullikine.github.io/fievel.png" alt="Shane Mulligan" /></a>
      <h1>Bodacious Blog</h1>
      
      <div class="app-header-social">
        
          <a target="_blank" href="https://github.com/mullikine"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg></a>
        
          <a target="_blank" href="https://linkedin.com/in/shane-mulligan-811b942b/"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-linkedin">
  <title>linkedin</title>
  <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle>
</svg></a>
        
          <a target="_blank" href="https://gitlab.com/mullikine"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-gitlab">
  <title>gitlab</title>
  <path d="M22.65 14.39L12 22.13 1.35 14.39a.84.84 0 0 1-.3-.94l1.22-3.78 2.44-7.51A.42.42 0 0 1 4.82 2a.43.43 0 0 1 .58 0 .42.42 0 0 1 .11.18l2.44 7.49h8.1l2.44-7.51A.42.42 0 0 1 18.6 2a.43.43 0 0 1 .58 0 .42.42 0 0 1 .11.18l2.44 7.51L23 13.45a.84.84 0 0 1-.35.94z"></path>
</svg></a>
        
          <a target="_blank" href="https://twitter.com/mullikine"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-twitter">
  <title>twitter</title>
  <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path>
</svg></a>
        
        <a href="https://mullikine.github.io/cv/">CV</a>
      </div>
<div class="highlights">
<a href="https://mullikine.github.io/posts/practical-macros-in-racket-and-how-to-work-with-them/">Practical macros in Racket</a>
<br />
<a href="https://mullikine.github.io/posts/generating-hyperlinks-for-glossaries-and-other-parsers-in-emacs/">Hyperlink generation in emacs</a>
<br />
<a href="https://mullikine.github.io/posts/github-search-with-bigquery/">Searching GitHub with BigQuery</a>

<br />
<a href="https://mullikine.github.io/posts/review-of-the-case-for-learned-index-structures/">Case for Learned Index Structures</a>
<br />
<a href="https://mullikine.github.io/posts/arbitrary-interpreters-for-babel/">Arbitrary interpreters for Babel</a>
<br />
<a href="https://mullikine.github.io/glossary.html">Glossary A-Z (298 topics)</a> <a href="https://github.com/mullikine/glossaries-gh">code</a>
<br />
<a href="https://mullikine.github.io/posts/dwarf-fortress-macros-with-emacs-and-tmux/">Automating Dwarf Fortress</a>
<br />
<a href="https://mullikine.github.io/posts/review-of-the-illustrated-transformer/">The Illustrated Transformer</a>
<br />
<a href="https://mullikine.github.io/codelingo-vs-linters/summary/">CodeLingo vs Linters</a>
<br />
<a class="big" href="https://infogetics.github.io/">Infogetics on GitHub</a>
<br />
<a class="big" href="https://github.com/semiosis">Semiosis on GitHub</a>
<br />
<a class="big" href="https://takaheai.github.io/">TakaheAI on GitHub</a>
<br />
<div class="taglist">

  <a class="tag" href="https://mullikine.github.io/tags/gpt/">GPT (Generative Pre-trained Transformer)</a>
<a class="tag" href="https://mullikine.github.io/tags/biosemiotics/">biosemiotics</a>
<a class="tag" href="https://mullikine.github.io/tags/xenolinguistics/">xenolinguistics</a>
<a class="tag big" href="https://mullikine.github.io/tags/emacs/">emacs</a>
<a class="tag" href="https://mullikine.github.io/tags/elisp/">elisp</a>
<a class="tag" href="https://mullikine.github.io/tags/racket/">racket</a>
<a class="tag" href="https://mullikine.github.io/tags/haskell/">haskell</a>
<a class="tag" href="https://mullikine.github.io/tags/nlp/">NLP</a>
<a class="tag" href="https://mullikine.github.io/tags/docker/">docker</a>
<a class="tag" href="https://mullikine.github.io/tags/feature-engineering/">feature-engineering</a>
<a class="tag big" href="https://mullikine.github.io/tags/ir/">IR</a>
<a class="tag" href="https://mullikine.github.io/tags/games/">games</a>
<a class="tag" href="https://mullikine.github.io/tags/data/">data</a>
<a class="tag" href="https://mullikine.github.io/tags/info/">info theory</a>
<a class="tag" href="https://mullikine.github.io/tags/probability/">probability</a>
<a class="tag" href="https://mullikine.github.io/tags/problog/">problog</a>
<a class="tag big" href="https://mullikine.github.io/tags/shell/">shell</a>

<a class="tag" href="https://mullikine.github.io/tags/tooling/">tooling</a>
<a class="tag" href="https://mullikine.github.io/tags/iac/">IaC</a>
<a class="tag big" href="https://mullikine.github.io/tags/facebook/">Facebook</a>
<a class="tag" href="https://mullikine.github.io/tags/wfh/">WFH</a>


<a class="tag" href="https://mullikine.github.io/tags/babel/">babel</a>

<a class="tag" href="https://mullikine.github.io/tags/gcp/">GCP</a>
<a class="tag big" href="https://mullikine.github.io/tags/github/">GitHub</a>
<a class="tag" href="https://mullikine.github.io/tags/parsers/">parsers</a>
<a class="tag" href="https://mullikine.github.io/tags/rust/">rust</a>
<a class="tag" href="https://mullikine.github.io/tags/cpp/">c++</a>
<a class="tag" href="https://mullikine.github.io/tags/review/">review</a>
<a class="tag" href="https://mullikine.github.io/tags/kaggle/">kaggle</a>
<a class="tag" href="https://mullikine.github.io/tags/dl/">deep learning</a>
<a class="tag" href="https://mullikine.github.io/tags/dsl/">DSL</a>
<a class="tag" href="https://mullikine.github.io/tags/music/">music</a>
<a class="tag" href="https://mullikine.github.io/tags/df/">dwarf fortress</a>
<a class="tag" href="https://mullikine.github.io/tags/spacy/">spacy</a>
<a class="tag" href="https://mullikine.github.io/tags/latex/">latex</a>
<a class="tag" href="https://mullikine.github.io/tags/nix/">Nix</a>
<a class="tag" href="https://mullikine.github.io/tags/diagrams/">diagrams</a>
<a class="tag" href="https://mullikine.github.io/tags/python/">python</a>
<a class="tag" href="https://mullikine.github.io/tags/neural-engineering/">neural-engineering</a>
<a class="tag" href="https://mullikine.github.io/tags/golang/">golang</a>
<a class="tag" href="https://mullikine.github.io/tags/codelingo/">codelingo</a>
<a class="tag" href="https://mullikine.github.io/tags/aws/">AWS</a>
<a class="tag" href="https://mullikine.github.io/tags/perl/">perl</a>
<a class="tag big" href="https://mullikine.github.io/tags/vim/">vim</a>
<a class="tag" href="https://mullikine.github.io/tags/telco/">telco</a>
<a class="tag" href="https://mullikine.github.io/tags/automation/">automation</a>
<a class="tag" href="https://mullikine.github.io/tags/optimisation/">optimisation</a>
<a class="tag" href="https://mullikine.github.io/tags/release/">release</a>
<a class="tag" href="https://mullikine.github.io/tags/dotnet/">.NET</a>
<a class="tag" href="https://mullikine.github.io/tags/csharp/">csharp</a>
<a class="tag big" href="https://mullikine.github.io/tags/uber/">Uber</a>
<a class="tag" href="https://mullikine.github.io/tags/math/">math</a>
<a class="tag" href="https://mullikine.github.io/tags/microsoft/">Microsoft</a>
<a class="tag big" href="https://mullikine.github.io/tags/neuralink/">Neuralink</a>
<a class="tag big" href="https://mullikine.github.io/tags/openai/">OpenAI</a>
<a class="tag" href="https://mullikine.github.io/tags/terminals/">terminals</a>
<a class="tag" href="https://mullikine.github.io/tags/transformer/">transformer</a>
<a class="tag big" href="https://mullikine.github.io/tags/codegen/">code-gen</a>
<a class="tag" href="https://mullikine.github.io/tags/rosie/">rosie</a>
<a class="tag" href="https://mullikine.github.io/tags/terraform/">Terraform</a>
<a class="tag" href="https://mullikine.github.io/tags/elasticsearch/">ELK</a>
<a class="tag" href="https://mullikine.github.io/tags/semmle/">Semmle</a>
<a class="tag" href="https://mullikine.github.io/tags/expect/">tcl/expect</a>
<a class="tag" href="https://mullikine.github.io/tags/solr/">solr</a>
</div>
</div>



</div>
<div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <div class="post-footer phone">
      <p>
        <a href="https://mullikine.github.io/">Latest articles</a>
        &nbsp;
        ⚔
        &nbsp;
        <a href="https://mullikine.github.io/tags/">Site Map</a>
      </p>
    </div>
    <header class="post-header">
      <h1 class ="post-title">Review of &#39;Google AI Blog: PEGASUS: A State-of-the-Art Model for Abstractive Text Summarization&#39;</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Jun 13, 2020
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          2 min read
        </div><div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <title>tag</title>
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line>
</svg>
          <a class="tag" href="https://mullikine.github.io/tags/nlp/">NLP</a></div></div>
    </header>
    

<link rel="stylesheet" type="text/css" href="https://mullikine.github.io/css/magit.css"/>

<script src="https://mullikine.github.io/js/mathjax-config.js"></script>
 
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML"></script>


    <div class="post-content">
      <dl>
<dt>Original article</dt>
<dd><a href="https://ai.googleblog.com/2020/06/pegasus-state-of-art-model-for.html">Google AI Blog: PEGASUS: A State-of-the-Art Model for Abstractive Text Summarization</a></dd>
<dt>Source code</dt>
<dd><a href="https://github.com/google-research/pegasus">GitHub - google-research/pegasus</a></dd>
<dt>text summarization</dt>
<dd>one of the most challenging tasks in natural language processing, involving understanding of long passages,
information compression, and language generation.</dd>
</dl>
<p>The dominant paradigm for training ML models
to do this is <code>seq2seq</code> learning, where a NN
learns to map input sequences to output
sequences.</p>
<p><code>seq2seq</code> models were initially developed using RNN.</p>
<p>Transformer <code>encoder-decoder</code> models have
recently become favored as they are more
effective at modeling the dependencies present
in the long sequences encountered in
summarization.</p>
<p><code>seq2seq</code></p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">RNN -&gt; &#34;Transformer encoder-decoder&#34;</code></pre></td></tr></table>
</div>
</div>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">+-----+     +-----------------------------+
| RNN | --&gt; | Transformer encoder-decoder |
+-----+     +-----------------------------+
</code></pre></div><ul>
<li>Transformer models combined with self-supervised pre-training, e.g.
<ul>
<li><a href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html">BERT</a>,</li>
<li><a href="https://openai.com/blog/better-language-models/">GPT-2</a>,</li>
<li><a href="https://arxiv.org/abs/1907.11692">RoBERTa</a>,</li>
<li><a href="https://arxiv.org/abs/1906.08237">XLNet</a>,</li>
<li><a href="https://ai.googleblog.com/2019/12/albert-lite-bert-for-self-supervised.html">ALBERT</a>,</li>
<li><a href="https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html">T5</a>,</li>
<li><a href="https://ai.googleblog.com/2020/03/more-efficient-nlp-model-pre-training.html">ELECTRA</a></li>
</ul>
</li>
</ul>
<h2 id="pegaus-pre-training-with-extracted-gap-sentences-for-abstractive-summarization">PEGAUS - Pre-training with Extracted Gap-sentences for Abstractive Summarization</h2>
<h3 id="a-self-supervised-objective-for-summarization">A Self-Supervised Objective for Summarization</h3>
<p>Our hypothesis is that the closer the pre-
training self-supervised objective is to the
final down-stream task, the better the fine-
tuning performance.</p>
<p>In PEGASUS pre-training, several whole
sentences are removed from documents and the
model is tasked with recovering them.</p>
<p>An example input for pre-training is a
document with missing sentences, while the
output consists of the missing sentences
concatenated together.</p>
<p>This is an incredibly difficult task that may
seem impossible, even for people, and we don&rsquo;t
expect the model to solve it perfectly.</p>
<p>However, such a challenging task encourages
the model to learn about language and general
facts about the world, as well as how to
distill information taken from throughout a
document in order to generate output that
closely resembles the fine-tuning
summarization task.</p>
<p>The advantage of this self-supervision is that
you can create as many examples as there are
documents, without any human annotation, which
is often the bottleneck in purely supervised
systems.</p>
<dl>
<dt>A self-supervised example for PEGASUS during pre-training.</dt>
<dd><img src="https://1.bp.blogspot.com/-TSor4o51jGI/Xt50lkj6blI/AAAAAAAAGDs/TrDe9jv13WEwk9NQNebQL63jtY8n6JFGwCLcBGAsYHQ/s1600/image1.gif" alt=""> <br />
The model is trained to output all the masked sentences.</dd>
</dl>
<h2 id="source-code">Source code</h2>
<p>Provides code to train on Google Cloud.</p>

    </div>
    <div class="post-footer">
        <p>
        <a href="https://mullikine.github.io/">Latest articles</a>
        &nbsp;
        ⚔
        &nbsp;
        <a href="https://mullikine.github.io/about/">About this weblog</a>
        &nbsp;
        ⚔
        &nbsp;
        <a href="https://asciinema.org/~mullikine">Asciinema recordings</a>
        &nbsp;
        ⚔
        &nbsp;
        <a href="https://mullikine.github.io/posts/blogs-and-vlogs/">Blogs and Vlogs</a>
        &nbsp;
        ⚔
        &nbsp;
        <a href="https://mullikine.github.io/cv/">CV</a>
        &nbsp;
        ⚔
        &nbsp;
        <a href="https://mullikine.github.io/tags/">Site Map</a>
        </p>
    </div>
  </article>

    </main>
  </body>
</html>
