<!doctype html>
<html lang="en-us">
  <head>
    <title>Review of The Illustrated Transformer // Bodacious Blog</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.59.0-DEV" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="John Doe" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://mullikine.github.io/css/main.min.05e80417f72996c0b102ae49f04ebb531302315f2100c700d2a95eb8c40cf172.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Review of The Illustrated Transformer"/>
<meta name="twitter:description" content="https://jalammar.github.io/illustrated-transformer/
Helpful glossary Multilayer perceptron Feed-Forward Neural Network FFNN Basically, these are multi-level logistic regression classifiers. Many layers of scales are separated by non-linearities. Can be used for as autoencoders. Can be used to train a classifier or extract functions as autoencoders. self-attention intra-attention [attention mechanism] Relates different positions of a single sequence in order to compute a representation of the sequence. An attention operation of a single sequence in order to calculate the representation of the very same sequence."/>

    <meta property="og:title" content="Review of The Illustrated Transformer" />
<meta property="og:description" content="https://jalammar.github.io/illustrated-transformer/
Helpful glossary Multilayer perceptron Feed-Forward Neural Network FFNN Basically, these are multi-level logistic regression classifiers. Many layers of scales are separated by non-linearities. Can be used for as autoencoders. Can be used to train a classifier or extract functions as autoencoders. self-attention intra-attention [attention mechanism] Relates different positions of a single sequence in order to compute a representation of the sequence. An attention operation of a single sequence in order to calculate the representation of the very same sequence." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mullikine.github.io/posts/review-of-the-illustrated-transformer/" />
<meta property="article:published_time" content="2019-10-19T00:00:00+13:00" />
<meta property="article:modified_time" content="2019-10-19T00:00:00+13:00" /><meta property="og:site_name" content="Bodacious Blog" />


  </head>
  <body>
    <header class="app-header">
      <a href="https://mullikine.github.io"><img class="app-header-avatar" src="http://mullikine.github.io/brainy.png" alt="John Doe" /></a>
      <h1>Bodacious Blog</h1>
      <p>biosemiotics, xenolingustics and emacs</p>
      <div class="app-header-social">
        
          <a target="_blank" href="https://github.com/mullikine"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg></a>
        
          <a target="_blank" href="https://linkedin.com/in/shane-mulligan-811b942b/"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-linkedin">
  <title>linkedin</title>
  <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle>
</svg></a>
        
          <a target="_blank" href="https://gitlab.com/mullikine"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-gitlab">
  <title>gitlab</title>
  <path d="M22.65 14.39L12 22.13 1.35 14.39a.84.84 0 0 1-.3-.94l1.22-3.78 2.44-7.51A.42.42 0 0 1 4.82 2a.43.43 0 0 1 .58 0 .42.42 0 0 1 .11.18l2.44 7.49h8.1l2.44-7.51A.42.42 0 0 1 18.6 2a.43.43 0 0 1 .58 0 .42.42 0 0 1 .11.18l2.44 7.51L23 13.45a.84.84 0 0 1-.35.94z"></path>
</svg></a>
        
          <a target="_blank" href="https://www.facebook.com/shrubgrub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-facebook">
  <title>facebook</title>
  <path d="M18 2h-3a5 5 0 0 0-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 0 1 1-1h3z"></path>
</svg></a>
        
          <a target="_blank" href="https://twitter.com/mullikine"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-twitter">
  <title>twitter</title>
  <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path>
</svg></a>
        
        <a href="https://mullikine.github.io/cv/">CV</a>
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">Review of The Illustrated Transformer</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Oct 19, 2019
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          3 min read
        </div></div>
    </header>
    <div class="post-content">
      

<p><a href="https://jalammar.github.io/illustrated-transformer/">https://jalammar.github.io/illustrated-transformer/</a></p>

<h2 id="helpful-glossary">Helpful glossary</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">Multilayer perceptron
Feed-Forward Neural Network
FFNN
    Basically, these are multi-level logistic
    regression classifiers.

    Many layers of scales are separated by
    non-linearities.

    Can be used for as autoencoders.

    Can be used to train a classifier or
    extract functions as autoencoders.

self-attention
intra-attention
    [attention mechanism]

    Relates different positions of a single
    sequence in order to compute a
    representation of the sequence.

    An attention operation of a single
    sequence in order to calculate the
    representation of the very same sequence.

    This concept has been very useful in NLP
    tasks such as Text summarization, Machine
    Translation and Image Description
    Generation.</code></pre></div>
<h3 id="optional-reading">Optional reading</h3>

<table>
<thead>
<tr>
<th>Topic</th>
<th>URL</th>
</tr>
</thead>

<tbody>
<tr>
<td>Self-attention</td>
<td><a href="https://medium.com/saarthi-ai/transformers-attention-based-seq2seq-machine-translation-a28940aaa4fe">Why do Transformers yield Superior Sequence to Sequence(Seq2Seq)Results?</a></td>
</tr>
</tbody>
</table>

<h2 id="high-level-overview">High level overview</h2>

<p>In a machine translation application, it would
take a sentence in one language, and output
its translation in another.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-dot" data-lang="dot">input [label=&#34;foreign language&#34;]
output [label=&#34;your language&#34;]

subgraph transformer {
    decoders [label=&#34;encoders: stack of N decoders&#34;]
    encoders [label=&#34;encoders: stack of N encoders&#34;] -&gt; decoders
}

input -&gt; encoders [label=input]
decoders -&gt; output [label=output]</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">  ∘━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━∘
  ┃       foreign language        ┃
  ∘━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━∘
    ┃
    ┃ input
    v
∘┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄∘
┆            transformer            ┆
┆                                   ┆
┆ ∘━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━∘ ┆
┆ ┃ encoders: stack of N encoders ┃ ┆
┆ ∘━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━∘ ┆
┆   ┃                               ┆
┆   ┃                               ┆
┆   v                               ┆
┆ ∘━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━∘ ┆
┆ ┃ encoders: stack of N decoders ┃ ┆
┆ ∘━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━∘ ┆
┆                                   ┆
∘┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄∘
    ┃
    ┃ output
    v
  ∘━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━∘
  ┃         your language         ┃
  ∘━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━∘</code></pre></div>
<h4 id="a-look-inside-the-encoder-stack">A look inside the encoder stack</h4>

<p>Sadly <span class="underline">nested</span> subgraphs don&rsquo;t render in ASCII.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">#+BEGIN_SRC graphviz-dot :filter dot-digraph :async :results verbatim drawer
  subgraph encoders {
      label = &#34;Parent&#34;;
      subgraph &#34;encoder1&#34; {
          f1[label=&#34;FFNN&#34;]
          a1[label=&#34;Self-Attention layer&#34;] -&gt; f1
      }
      subgraph &#34;encoder2&#34; {
          f2[label=&#34;FFNN&#34;]
          a2[label=&#34;Self-Attention layer&#34;] -&gt; f2
      }

      f1 -&gt; a2
  }
#+END_SRC</code></pre></div>
<p>Each stack contains <code>N</code> encoders.</p>

<p>Each encoder contains a <span class="underline">self-attention layer</span> and an <span class="underline">FFNN</span>:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-graphviz-dot" data-lang="graphviz-dot">subgraph &#34;encoder1&#34; {
    f1[label=&#34;FFNN&#34;]
    a1[label=&#34;Self-Attention layer&#34;] -&gt; f1
}
subgraph &#34;encoder2&#34; {
    f2[label=&#34;FFNN&#34;]
    a2[label=&#34;Self-Attention layer&#34;] -&gt; f2
}

f1 -&gt; a2
f2 -&gt; encoderN [label=&#34;...&#34;]</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">∘┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄∘
┆         encoder1         ┆
┆                          ┆
┆ ∘━━━━━━━━━━━━━━━━━━━━━━∘ ┆
┆ ┃ Self━Attention layer ┃ ┆
┆ ∘━━━━━━━━━━━━━━━━━━━━━━∘ ┆
┆   ┃                      ┆
┆   ┃                      ┆
┆   v                      ┆
┆ ∘━━━━━━━━━━━━━━━━━━━━━━∘ ┆
┆ ┃         FFNN         ┃ ┆
┆ ∘━━━━━━━━━━━━━━━━━━━━━━∘ ┆
┆                          ┆
∘┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄∘
    ┃
    ┃
    v
∘┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄∘
┆         encoder2         ┆
┆                          ┆
┆ ∘━━━━━━━━━━━━━━━━━━━━━━∘ ┆
┆ ┃ Self━Attention layer ┃ ┆
┆ ∘━━━━━━━━━━━━━━━━━━━━━━∘ ┆
┆   ┃                      ┆
┆   ┃                      ┆
┆   v                      ┆
┆ ∘━━━━━━━━━━━━━━━━━━━━━━∘ ┆
┆ ┃         FFNN         ┃ ┆
┆ ∘━━━━━━━━━━━━━━━━━━━━━━∘ ┆
┆                          ┆
∘┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄∘
    ┃
    ┃ ...
    v
  ∘━━━━━━━━━━━━━━━━━━━━━━∘
  ┃       encoderN       ┃
  ∘━━━━━━━━━━━━━━━━━━━━━━∘</code></pre></div>
<p>A <span class="underline">self-attention layer</span> helps the encoder
look at other words in the input sentence as
it encodes a specific word.</p>

<p>The exact same <code>FFNN</code> is independently applied
to each position. If you imagine an encoder is
a <code>CNN</code>, you can think of the self-attention
layer as being the sliding window but it has
context of the entire text, not just a few
words around it. The <code>FFNN</code></p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
